syntax = "proto3";

message OllamaGenerateMessage {
  string role = 1;
  string content = 2;
  repeated string images = 3;
}

message OllamaModelOptions {
  optional float temperature = 1;
  optional int32 seed = 2;
  repeated string stop = 6;
}

message OllamaCompletionRequest {
  string model = 1;
  string prompt = 2;
  optional bool stream = 3;
  string format = 4;
  OllamaModelOptions options = 5;
  bool raw = 6;
}

message OllamaCompletionResponse {
  string model = 1;
  string created_at = 2;
  repeated int32 context = 3;
  string response = 4;
  bool done = 6;
  uint64 total_duration = 7;
  uint64 load_duration = 8;
  int32 prompt_eval_count = 9;
  uint64 prompt_eval_duration = 10;
  int32 eval_count = 11;
  uint64 eval_duration = 12;
}

message OllamaChatCompletionRequest {
  string model = 1;
  repeated OllamaGenerateMessage messages = 2;
  // mark bool as or it's ignored if value is false
  optional bool stream = 3;
  string format = 4;
  OllamaModelOptions options = 5;
}

message OllamaChatCompletionResponse {
  string model = 1;
  string created_at = 2;
  repeated int64 context = 3;
  OllamaGenerateMessage message = 5;
  bool done = 6;
  int64 total_duration = 7;
  int64 load_duration = 8;
  int64 prompt_eval_count = 9;
  int64 prompt_eval_duration = 10;
  int64 eval_count = 11;
  int64 eval_duration = 12;
}

message OllamaEmbeddingRequest {
  string model = 1;
  string prompt = 2;
  OllamaModelOptions options = 3;
}

message OllamaEmbeddingResponse {
  repeated float embedding = 1;
}


